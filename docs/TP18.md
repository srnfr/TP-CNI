# Audit Mode

Ce TP se déroule sur un cluster <ins>**DigitalOcean**<ins>.

## Sommaire

* [But du TP](#but-du-tp)
* [Deployer l'application demo Star Wars](#deployer-lapplication-demo-star-wars)
* [Activer le Policy Audit Mode pour le Endpoint DeathStar](#activer-le-policy-audit-mode-pour-le-endpoint-deathstar)
* [Créer et appliquer une NetPol laxiste](#créer-et-appliquer-une-netpol-laxiste)
* [Tester l'accès](#tester-laccès)
* [Creer une politique ingressDeny pour bloquer l'alliance](#creer-une-politique-ingressdeny-pour-bloquer-lalliance)
* [Tester l'accès pour l'alliance](#tester-laccès-pour-lalliance)
* [Cleanup](#cleanup)

## But du TP

Comprendre le fonctionnement du Policy Audit Mode.

## Deployer l'application demo Star Wars

```bash
kubectl create -f https://raw.githubusercontent.com/cilium/cilium/HEAD/examples/minikube/http-sw-app.yaml -n default
```

Réduisons le nombre de DeathStar à 1 pour faciliter le TP :
```bash
kubectl scale deployment deathstar --replicas=1 -n default
```

## Activer le Policy Audit Mode pour le Endpoint DeathStar

Déterminons l'ID du Endpoint (EP) nommé DeathStar, pour cela on recherche sa combinaison unique de labels :

```bash
kubectl get pods --show-labels
NAME                        READY   STATUS    RESTARTS   AGE     LABELS
[..]
deathstar-fxxxx   1/1     Running   0          13m     app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=f694cf746
[..]
```

```bash
kubectl exec -n kube-system -ti ds/cilium -- cilium endpoint get -l k8s:class=deathstar,k8s:org=empire -o jsonpath={[].id}
```

L'idéal aurait été de traiter de traiter le résultat avec l'outil `jq` (disponible sur Linux) avec le filtre ".[].id", ou d'utiliser un [visualisateur en ligne de JSON](http://jsonviewer.stack.hu/), mais là, on utilise l'argument "-o jsonpath" pour plus de simplicité.

Un moyen alternative est de récupérer l'ID de l'EP en utilisant le nom du Pod :

```bash
kubectl get cep -o jsonpath="{.items[?(@.metadata.name=='deathstar-xxxx')].status.id}"
```

Bref, dans notre cas, le EP DeathStar a l'ID yyyy.

Déterminons le Node nnnn qui porte notre EP DeathStar :

```bash
kubectl get pod/deathstar-xxxx -o wide
```

Déterminons le nom du Pod cilium-cccc qui tourne sur ce même Node nnnn :

```bash
kubectl get pod -n kube-system -o wide 
```

Activons l'Audit Mode pour cet EP sur ce Node :

```bash
kubectl exec -n kube-system -ti pod/cilium-cccc -- cilium endpoint config yyyy PolicyAuditMode=Enabled
```

## Créer et appliquer une NetPol laxiste

Voici son contenu :

```yaml
## cnp-rule1.yaml
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "rule1"
spec:
  description: "Allow any"
  endpointSelector:
    matchLabels:
      org: empire
      class: deathstar
  ingress:
  - toPorts:
    - ports:
      - port: "80"
        protocol: TCP
```

L'appliquer

```bash
kubectl apply -f cnp-rule1.yaml
```

On vérifie :

```bash
kubectl get cnp
```

## Tester l'accès

Dans une première fenetre, surveillons les logs en rapport avec notre EP :

```bash
kubectl exec -n kube-system -ti cilium-cccc -- cilium monitor --to yyyy -t policy-verdict
```

Dans une seconde fenêtre : On constate que les accès sont autorisés pour Tiefighter et X-Wing

```bash
kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
```

```bash
kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
```

## Creer une politique ingressDeny pour bloquer l'alliance

Voici son contenu :

```yaml
## cnp-rule2.yaml
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "rule2"
spec:
  description: "Deny alliance"
  endpointSelector:
    matchLabels:
      org: empire
      class: deathstar
  ingressDeny:
  - fromEndpoints:
    - matchLabels:
        org: alliance
    toPorts:
    - ports:
      - port: "80"
        protocol: TCP
```

Appliquer la politique

```bash
kubectl apply --recursive -f cnp-rule2.yaml
```

Vérfier que les 2 politiques sont bien appliquées

```bash
kubectl get cnp  
```

## Tester l'accès pour l'alliance

```bash
kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
```

L'accès est normalement bien autorisé pour Tiefighter.

```bash
kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
```

Vous constatez que l'accès n'est pas filtré pour xwing !!!  
Regardons les logs cilium monitor qui apparaissent dans la première fenêtre:  
```
Press Ctrl-C to quit  
level=info msg="Initializing dissection cache..." subsys=monitor 
Policy verdict log: flow 0x49bb3bc7 local EP ID 533, remote ID 17111, proto 6, ingress, action allow, match L4-Only, 10.244.0.226:45112 -> 10.244.0.164:80 tcp SYN  
Policy verdict log: flow 0x677bd020 local EP ID 533, remote ID 6930, proto 6, ingress, action audit, match L3-L4, 10.244.0.222:52466 -> 10.244.0.164:80 tcp SYN  
```

Le 1er flux correspond à Tiefighter.  
Le second à Xwing.  
Notez les valeurs différentes pour `action` suivant l'autorisation (=`allow`) et l'audit (normalement `drop`)

## Conclusion

Le mode Audit n'est pas à utiliser en production : il permet de tester les politiques avant de les appliquer en mode "réel" mais laisse passer les flux tout en les marquant dans les logs !

## Cleanup

Désactivons l' Audit Mode

```bash
kubectl exec -n kube-system -ti pod/cilium-cccc  -- cilium endpoint config yyyy PolicyAuditMode=Disabled
```

Testons si les flux sont bien autorisés ou interdits comme prévu :

```bash
kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
```

```bash
kubectl exec xwing -- curl -sv -XPOST deathstar.default.svc.cluster.local/v1/request-landing
```

XWing est bien bloqué, Tiefighter est bien autorisé. Ouf ! (The Empire did nothing wrong)

Détruisons maintenant le déploiement et enlever les CNP :

```bash
kubectl delete deployment/deathstar 
kubectl delete cnp/rule1
kubectl delete cnp/rule2
```

---

[Revenir au sommaire](../README.md)
